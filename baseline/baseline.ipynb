{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "import string\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stolen from notebook9\n",
    "filename = \"glove.6B.50d.txt\"\n",
    "\n",
    "embeddings = {}\n",
    "with open(filename,'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        elements = line.split();\n",
    "        word = elements[0];\n",
    "        vector = np.asarray(elements[1:],\"float32\")\n",
    "        embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    text (string): raw text from data\n",
    "\n",
    "    Returns:\n",
    "    string: string with no punctuation and\n",
    "            only contains words in embeddings\n",
    "    \"\"\"\n",
    "    no_puncuation = \"\"\n",
    "    for char in text:\n",
    "        if char not in string.punctuation:\n",
    "            no_puncuation += char\n",
    "    no_unknowns = \"\"\n",
    "    for word in no_puncuation.split():\n",
    "        if word in embeddings:\n",
    "             no_unknowns += word.lower() + \" \"\n",
    "    return no_unknowns\n",
    "\n",
    "def mean_emb(text):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    text (string): raw text from data\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray(50,): mean embedding of text\n",
    "    \"\"\"\n",
    "    pre = preprocess(text).split()\n",
    "    sum_emb = np.zeros(50,)\n",
    "    for word in pre:\n",
    "        sum_emb += embeddings[word]\n",
    "    mean_emb = sum_emb/50\n",
    "    return mean_emb\n",
    "\n",
    "def gnb_acc(train, test, embeddings=embeddings):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    train (dict): texts and labels for training data\n",
    "    test (dict): texts and labels for test data\n",
    "    embeddings (dict): glove embeddings\n",
    "    \n",
    "    Returns:\n",
    "    numpy.float64: accuracy score\n",
    "    \"\"\"\n",
    "    train_emb = np.array([mean_emb(text) for text in train['texts']])\n",
    "    test_emb = np.array([mean_emb(text) for text in test['texts']])\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train_emb, train['labels'])\n",
    "\n",
    "    pred_labels = clf.predict(test_emb)\n",
    "    acc = accuracy_score(test['labels'], pred_labels)\n",
    "    return acc\n",
    "\n",
    "def pca_from_data(train_data, n_components=2):\n",
    "    train_emb = np.array([mean_emb(text) for text in train_data['texts']])\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit(train_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = np.load('../spam_data.npz')\n",
    "spam_train, spam_test = {}, {}\n",
    "spam_train['texts'], spam_train['labels'] = spam_data['train_texts'], spam_data['train_labels']\n",
    "spam_test['texts'], spam_test['labels'] = spam_data['test_texts'], spam_data['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_gnb_acc = gnb_acc(spam_train, spam_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_emb_pca = pca_from_data(spam_train, n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = np.load('../news_data.npz')\n",
    "news_train, news_test = {}, {}\n",
    "news_train['texts'], news_train['labels'] = news_data['train_texts'], news_data['train_labels']\n",
    "news_test['texts'], news_test['labels'] = news_data['test_texts'], news_data['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_gnb_acc = gnb_acc(news_train, news_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_emb_pca = pca_from_data(news_train, n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_gnb_acc"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bit88b66cf7d91d4746a5b93fe63573396a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}