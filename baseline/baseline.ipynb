{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "import string\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stolen from notebook9\n",
    "filename = \"glove.6B.50d.txt\"\n",
    "\n",
    "embeddings = {}\n",
    "with open(filename,'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        elements = line.split();\n",
    "        word = elements[0];\n",
    "        vector = np.asarray(elements[1:],\"float32\")\n",
    "        embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    text (string): raw text from data\n",
    "\n",
    "    Returns:\n",
    "    string: string with no punctuation and\n",
    "            only contains words in embeddings\n",
    "    \"\"\"\n",
    "    no_puncuation = \"\"\n",
    "    for char in text:\n",
    "        if char not in string.punctuation:\n",
    "            no_puncuation += char\n",
    "    no_unknowns = \"\"\n",
    "    for word in no_puncuation.split():\n",
    "        if word in embeddings:\n",
    "             no_unknowns += word.lower() + \" \"\n",
    "    return no_unknowns\n",
    "\n",
    "def mean_emb(text):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    text (string): raw text from data\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray(50,): mean embedding of text\n",
    "    \"\"\"\n",
    "    pre = preprocess(text).split()\n",
    "    sum_emb = np.zeros(50,)\n",
    "    for word in pre:\n",
    "        sum_emb += embeddings[word]\n",
    "    mean_emb = sum_emb/50\n",
    "    return mean_emb\n",
    "\n",
    "def gnb_acc(train, test, embeddings=embeddings):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    train (dict): texts and labels for training data\n",
    "    test (dict): texts and labels for test data\n",
    "    embeddings (dict): glove embeddings\n",
    "    \n",
    "    Returns:\n",
    "    numpy.float64: accuracy score\n",
    "    \"\"\"\n",
    "    train_emb = np.array([mean_emb(text) for text in train['texts']])\n",
    "    test_emb = np.array([mean_emb(text) for text in test['texts']])\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train_emb, train['labels'])\n",
    "\n",
    "    pred_labels = clf.predict(test_emb)\n",
    "    acc = accuracy_score(test['labels'], pred_labels)\n",
    "    return acc\n",
    "\n",
    "def pca_from_data(train_data, n_components=2):\n",
    "    train_emb = np.array([mean_emb(text) for text in train_data['texts']])\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit(train_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = np.load('../spam_data.npz')\n",
    "spam_train, spam_test = {}, {}\n",
    "spam_train['texts'], spam_train['labels'] = spam_data['train_texts'], spam_data['train_labels']\n",
    "spam_test['texts'], spam_test['labels'] = spam_data['test_texts'], spam_data['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_gnb_acc = gnb_acc(spam_train, spam_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_emb_pca = pca_from_data(spam_train, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 6.53549890e-02,  3.68500225e-02,  1.54147883e-02,\n        -5.51702707e-02,  1.10187020e-01, -7.82964304e-04,\n        -1.03458807e-01,  9.56411650e-03, -5.24262595e-02,\n         1.11112533e-02, -1.92557189e-02,  5.71975506e-02,\n        -8.79173997e-02, -2.38906946e-02,  1.48200192e-01,\n         7.21708748e-02,  2.11289846e-02,  6.34522999e-04,\n        -4.51801575e-02, -1.21190684e-01, -1.36129547e-02,\n         7.38692509e-02,  8.60282036e-02,  2.49866951e-02,\n         8.74454222e-02, -4.15811176e-01, -1.15100740e-01,\n         2.69540644e-02,  1.07312790e-01, -1.19225767e-01,\n         7.98985039e-01,  9.27009875e-02, -9.33973592e-02,\n        -3.33979404e-02,  6.56485077e-04, -2.35213182e-02,\n         4.10189642e-02,  3.51006577e-02,  3.54274521e-02,\n        -6.59866294e-02, -2.51884566e-02,  1.61866635e-02,\n        -9.65482938e-03,  6.09723788e-02, -6.18977250e-04,\n         1.88980633e-02, -2.59761998e-02, -3.60189545e-02,\n        -1.05510492e-02,  4.51374883e-02],\n       [ 1.40107097e-02,  8.51359840e-02,  8.25617136e-02,\n         2.13103321e-01, -6.43032761e-02,  1.11133575e-01,\n        -7.39853608e-02, -1.76767783e-01,  1.27998932e-01,\n        -7.69094176e-02,  5.00678394e-02, -2.01178057e-01,\n         1.08931608e-01, -2.37164529e-02, -1.13123201e-01,\n        -1.43140105e-01, -1.49025449e-01, -9.86663577e-02,\n        -2.07122156e-01,  1.06002993e-01,  2.36451203e-01,\n        -2.19774337e-01, -1.17994379e-01, -4.05900004e-02,\n        -3.18939169e-01,  5.00907483e-02,  2.53200120e-01,\n        -1.74533013e-01, -2.33449732e-01,  2.05233982e-01,\n         3.41839909e-01, -1.26753683e-01,  3.43347408e-03,\n        -2.49765198e-02,  1.20024795e-01,  1.22943967e-02,\n         2.95043315e-02, -5.52773825e-02, -1.24021126e-01,\n        -4.10528204e-03,  1.22452123e-01, -2.97596958e-03,\n         6.11132198e-02, -1.15318748e-01, -1.26690291e-01,\n         5.89949953e-02,  8.31389591e-03,  1.41502287e-01,\n         4.27566318e-02, -1.84169717e-01]])"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "spam_emb_pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = np.load('../news_data.npz')\n",
    "news_train, news_test = {}, {}\n",
    "news_train['texts'], news_train['labels'] = news_data['train_texts'], news_data['train_labels']\n",
    "news_test['texts'], news_test['labels'] = news_data['test_texts'], news_data['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_gnb_acc = gnb_acc(news_train, news_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_emb_pca = pca_from_data(news_train, n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_gnb_acc"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bit88b66cf7d91d4746a5b93fe63573396a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}